
# DualCache

> **Status: Experimental / Proof of Concept**
>
> *A high-performance, concurrency-friendly caching architecture designed for read-heavy, power-law distributed workloads.*

## ğŸ“– Introduction

**DualCache** is a Rust-based caching library that challenges the traditional LRU/LFU implementations. Instead of relying on complex lock-free linked lists or micro-managed atomic memory orderings, DualCache leverages a **Blue-Green Deployment Architecture** (Double Buffering) to separate reads from writes completely.

This design eliminates reader lock contention and optimizes for **CPU Cache Locality** by using contiguous memory layouts (`Vec`) instead of pointer chasing. It is specifically engineered for systems where **throughput** and **tail latency stability** are critical, such as high-frequency trading systems, blockchain state storage, and high-traffic web services.

## ğŸš€ Key Features

### 1. Blue-Green Architecture (Read-Write Splitting)
*   **Zero-Contention Reads:** Utilizes a `Main` (Writer) and `Sub` (Reader) structure. Readers access a "Snapshot" of the data, ensuring `O(1)` wait-free access without being blocked by ongoing writes or evictions.
*   **Lazy Consistency:** Updates are batched and synchronized based on a "materiality" threshold, prioritizing system throughput over immediate strong consistency.

### 2. Statistical Eviction Protocol
*   **Mean-Based Threshold:** Instead of a rigid LRU queue, eviction is determined by dynamic statistical analysis (Global Counter Sum / Count). This effectively handles **Power-Law (Zipfian) Distributions** where "legacy authorities" (historically hot items) should not be evicted due to temporary inactivity.
*   **Legacy Protection:** A "Grandfather Clause" mechanism prevents high-value data from being flushed out by short-term traffic spikes (Scan Resistance).

### 3. Hardware-Aware Optimization
*   **Vec > Linked List:** All data resides in contiguous `Vec` structures. Reordering is done via `swap` or memory rotation, maximizing **L1/L2 Cache Hits** and avoiding the expensive pointer chasing found in traditional cache implementations.
*   **Simplicity by Design:** Intentionally avoids complex `Relaxed`/`Acquire` atomic orderings in favor of a macro-architectural design that eliminates the *need* for fine-grained synchronization.

### 4. Batching & Compression (Log Compaction)
*   **DeqVec Queue:** Write operations and promotion requests are buffered in a queue.
*   **Noise Filtering:** The system employs a "Log Compaction" strategy to merge redundant updates (e.g., +1, +1, +1 â†’ +3) before applying them, significantly reducing write amplification.

## ğŸ› ï¸ Architecture Overview

```rust
pub struct DualCache<K, V> {
    // The "Writer" - Handles mutations, evictions, and heavy lifting.
    main: Cache<K, V>, 
    
    // The "Reader" - A lightweight, read-only snapshot for high-throughput access.
    sub: Cache<K, V>,  
    
    // Asynchronous control plane for handling batched updates.
    lazy_update: DeqVec, 
}
```

### The "Sweet Spot" Philosophy
DualCache is built on the belief that **Architecture > Micro-optimization**. By isolating readers from writers and using statistical averages for eviction, we achieve a system that is:
1.  **Robust:** Resistant to cache thrashing.
2.  **Predictable:** Flat latency curves with minimal jitter.
3.  **Maintainable:** Simple, reasoning-friendly code without `unsafe` spaghetti.

## ğŸ“¦ Usage

*(Note: The API is subject to change as this is a Proof of Concept)*

```rust
use dual_cache::DualCache;
use std::sync::Arc;

fn main() {
    // Initialize DualCache
    let cache = DualCache::new();

    // Insert data (Goes to Main, eventually synced to Sub)
    cache.insert("user_123", "SessionData");

    // High-concurrency read (Hits Sub, wait-free)
    if let Some(value) = cache.get("user_123") {
        println!("Found: {}", value);
    }
    
    // The daemon/scheduler handles eviction and sync in the background
    // based on statistical analysis of traffic patterns.
}
```

## ğŸ”® Roadmap

*   [ ] **Micro-Benchmarks:** Comparative analysis against `moka`, `dashmap`, and standard `RwLock`.
*   [ ] **Fuzz Testing:** Using `loom` to verify concurrency safety under extreme chaos.
*   [ ] **Adaptive Thresholds:** Implementing linear regression to predict traffic gaps for optimal sync timing.

## ğŸ“„ License

[PolyForm Noncommercial License 1.0.0](https://polyformproject.org/licenses/noncommercial/1.0.0/)
---
**Disclaimer:** This project is an architectural study in high-performance system design. While the logic is sound, it is currently in an experimental phase. Contributions and discussions are welcome.

## ğŸ¤–AI generate code promt

```
DualCache è¨­è¨ˆåº•ç¨¿
-K,Vå‹æ…‹ï¼š
Arcï¼ˆZero-copy cloningï¼‰
-mapçµæ§‹ï¼š
è³‡æ–™ä¸»è¦å„²å­˜åœ¨arenaå¯ä»¥ä¿å­˜æª”æ¡ˆä½ç½®ä»¥åŠå°æ‡‰æ¬„ä½
-æ’åç†±é»ï¼š
æ¯å€‹å‘¼å«ç„¡æ¢ä»¶å¾€å‰arena swap
-ç´¯ç©æ¬¡æ•¸ï¼š
ç´¯ç©å‘¼å«æ¬¡æ•¸è¨ˆç®—å¹³å‡
-å¹³å‡æ·˜æ±°ï¼š
åˆ°é”arena capacity evict_point ä»¥ä¸‹  truncate 
-ç´¯ç©è±å…ï¼š
æœ‰æ™‚é«˜ç´¯ç©çš„æœƒæ‰è½å¹³å‡å€¼ä»¥ä¸‹çš„arenaä½ç½®å‰‡ä¿åº•evict_pointä¹‹å‰
-éæœŸåˆ·æ–°:
æ’ç¨‹æ¯å¤©0:00æª¢æŸ¥time_stamp æ ¹æ“šarena åˆ·æ–°hashmap index ä¸¦ä¸”åŸ·è¡Œ counter >> 1
-æ˜ åƒå­˜å–ï¼š
Blue-Green Deploymentå¿«å–æ¶æ§‹çš„é¿å…hashmapé–
-æ–°å¢è±å…ï¼š
arena.len> capacity/2 æ™‚ æ–°å¢è³‡æ–™appendå¾Œevict_point+1 èˆ‡å…¶äº’æ›ä½ç½®
-evict_pointåˆ·æ–°ï¼š
arena.len> capacity/2 æ™‚ æ¯æ¬¡å‘¼å«å…¶ä»–è³‡æ–™æª¢æŸ¥evict_point counter æ˜¯å¦å°æ–¼avg å¦å‰‡evict_point +1


#[derive(Clone, Debug)]
pub struct Node<K, V> {
    pub key: K, //æª”æ¡ˆè·¯å¾‘å’Œæ¬„ä½åç¨±
    pub value: V, //è³‡æ–™
    pub counter: u64, //å‘¼å«æ¬¡æ•¸
    pub time_stamp: u64, //å®šæœŸéŠ·æ¯€
}

struct Cache<K, V>
where
    K: Hash + Eq,
{
    arena: Vec<Node<K, V>>, //ç†±é»å„²å­˜æ’åº 
    index: HashMap<K, usize>, //ç´¢å¼• 
    counter_sum: usize, //å‘¼å«ç¸½å’Œ é è¨­ï¼š0
    evict_point:usize, //å¹³å‡å°æ‡‰ç¯€é» é è¨­ï¼šcapacity/2
    capacity:usize, //è‡ªå®šç¾©å®¹å™¨
}

pub struct DualCache<K, V>
where
    K: Hash + Eq + Clone,
{
    main: Mutex<Cache<K, V>>,// æ“ä½œ
    mirror: Arcswap<Cache<K, V>>, //æ˜ å°„æŸ¥è©¢
    lazy_update:Mutex<VecDeque<CacheAction<K>>>, //mainæ“ä½œç·©è¡
}

impl DualCache{
    fn daemon;
}
```

 
