
# DualCache

> **Status: Experimental / Proof of Concept**
>
> *A high-performance, concurrency-friendly caching architecture designed for read-heavy, power-law distributed workloads.*

## ğŸ“– Introduction

**DualCache** is a Rust-based caching library that challenges the traditional LRU/LFU implementations. Instead of relying on complex lock-free linked lists or micro-managed atomic memory orderings, DualCache leverages a **Blue-Green Deployment Architecture** (Double Buffering) to separate reads from writes completely.

This design eliminates reader lock contention and optimizes for **CPU Cache Locality** by using contiguous memory layouts (`Vec`) instead of pointer chasing. It is specifically engineered for systems where **throughput** and **tail latency stability** are critical, such as high-frequency trading systems, blockchain state storage, and high-traffic web services.

## ğŸš€ Key Features

### 1. Blue-Green Architecture (Read-Write Splitting)
*   **Zero-Contention Reads:** Utilizes a `Main` (Writer) and `Sub` (Reader) structure. Readers access a "Snapshot" of the data, ensuring `O(1)` wait-free access without being blocked by ongoing writes or evictions.
*   **Lazy Consistency:** Updates are batched and synchronized based on a "materiality" threshold, prioritizing system throughput over immediate strong consistency.

### 2. Statistical Eviction Protocol
*   **Mean-Based Threshold:** Instead of a rigid LRU queue, eviction is determined by dynamic statistical analysis (Global Counter Sum / Count). This effectively handles **Power-Law (Zipfian) Distributions** where "legacy authorities" (historically hot items) should not be evicted due to temporary inactivity.
*   **Legacy Protection:** A "Grandfather Clause" mechanism prevents high-value data from being flushed out by short-term traffic spikes (Scan Resistance).

### 3. Hardware-Aware Optimization
*   **Vec > Linked List:** All data resides in contiguous `Vec` structures. Reordering is done via `swap` or memory rotation, maximizing **L1/L2 Cache Hits** and avoiding the expensive pointer chasing found in traditional cache implementations.
*   **Simplicity by Design:** Intentionally avoids complex `Relaxed`/`Acquire` atomic orderings in favor of a macro-architectural design that eliminates the *need* for fine-grained synchronization.

### 4. Batching & Compression (Log Compaction)
*   **DeqVec Queue:** Write operations and promotion requests are buffered in a queue.
*   **Noise Filtering:** The system employs a "Log Compaction" strategy to merge redundant updates (e.g., +1, +1, +1 â†’ +3) before applying them, significantly reducing write amplification.

## ğŸ› ï¸ Architecture Overview

```rust
pub struct DualCache<K, V> {
    // The "Writer" - Handles mutations, evictions, and heavy lifting.
    main: Cache<K, V>, 
    
    // The "Reader" - A lightweight, read-only snapshot for high-throughput access.
    sub: Cache<K, V>,  
    
    // Asynchronous control plane for handling batched updates.
    lazy_update: DeqVec, 
}
```

### The "Sweet Spot" Philosophy
DualCache is built on the belief that **Architecture > Micro-optimization**. By isolating readers from writers and using statistical averages for eviction, we achieve a system that is:
1.  **Robust:** Resistant to cache thrashing.
2.  **Predictable:** Flat latency curves with minimal jitter.
3.  **Maintainable:** Simple, reasoning-friendly code without `unsafe` spaghetti.

## ğŸ“¦ Usage

*(Note: The API is subject to change as this is a Proof of Concept)*

```rust
use dual_cache::DualCache;
use std::sync::Arc;

fn main() {
    // Initialize DualCache
    let cache = DualCache::new();

    // Insert data (Goes to Main, eventually synced to Sub)
    cache.insert("user_123", "SessionData");

    // High-concurrency read (Hits Sub, wait-free)
    if let Some(value) = cache.get("user_123") {
        println!("Found: {}", value);
    }
    
    // The daemon/scheduler handles eviction and sync in the background
    // based on statistical analysis of traffic patterns.
}
```

## ğŸ”® Roadmap

*   [ ] **Micro-Benchmarks:** Comparative analysis against `moka`, `dashmap`, and standard `RwLock`.
*   [ ] **Fuzz Testing:** Using `loom` to verify concurrency safety under extreme chaos.
*   [ ] **Adaptive Thresholds:** Implementing linear regression to predict traffic gaps for optimal sync timing.

## ğŸ“„ License

[PolyForm Noncommercial License 1.0.0](https://polyformproject.org/licenses/noncommercial/1.0.0/)
---
**Disclaimer:** This project is an architectural study in high-performance system design. While the logic is sound, it is currently in an experimental phase. Contributions and discussions are welcome.

##AI generate code promt

```
Cache devise
K,Vå‹æ…‹ï¼š
Arc
mapçµæ§‹ï¼š
è³‡æ–™ä¸»è¦å„²å­˜åœ¨hashmapå¯ä»¥ä¿å­˜æª”æ¡ˆä½ç½®ä»¥åŠå°æ‡‰æ¬„ä½
æ’åç†±é»ï¼š
æ¯å€‹å‘¼å«ç„¡æ¢ä»¶å¾€å‰arena swap
ç´¯ç©æ¬¡æ•¸ï¼š
ç´¯ç©å‘¼å«æ¬¡æ•¸è¨ˆç®—å¹³å‡
å¹³å‡æ·˜æ±°ï¼š
è¨˜æ†¶é«”æ»¿äº†evict point ä»¥ä¸‹çš„arena  truncate æ¯æ¬¡å‘¼å«æ™‚ ç¢ºèª evict_point node counter å¤§ç´„ avgæ˜¯å‰‡ç„¡æ¢ä»¶å¾€å¾Œé¿å…avgè¢«æ‰­æ›²
ç´¯ç©è±å…ï¼š
æœ‰æ™‚é«˜ç´¯ç©çš„æœƒæ‰è½å¹³å‡å€¼ä»¥ä¸‹çš„arenaä½ç½®å‰‡ä¿åº•evict pointä¹‹å‰
éæœŸåˆ·æ–°:
logè¼‰å…¥æ™‚é–“æ’ç¨‹æ¯å¤©0:00æª¢æŸ¥éæœŸè³‡æ–™ æ ¹æ“šarena åˆ·æ–°hashmap ä¸¦ä¸”åŸ·è¡ŒÂ counter >> 1
æ˜ åƒå­˜å–ï¼š
Blue-Green Deploymentå¿«å–æ¶æ§‹çš„é¿å…hashmapé–

#[derive(Clone, Debug)]
pub struct Node<K, V> {
    pub key: K,//æª”æ¡ˆè·¯å¾‘å’Œæ¬„ä½åç¨±
    pub value: V,//è³‡æ–™
    pub counter: f64,//å‘¼å«æ¬¡æ•¸
    pub time_stamp: usize, //å®šæœŸéŠ·æ¯€
}

struct Cache<K, V>
where
    K: Hash + Eq,
{
    arena: Vec<Node<K, V>>,//ç†±é»æ’åº
    index: HashMap<K, usize>,//ç´¢å¼•
    counter_sum: f64,//å‘¼å«ç¸½å’Œ 
    evict_point:usize,//è¨ˆç®—å‘¼å«å¹³å‡ä¸¦ä¸”truncateä¹‹å¾Œçš„vec 
    lazy_update:DeqVec, //mainæ“ä½œç·©è¡
}

pub trait CacheOps
{
    fn read;
    fn create; 
    fn delete; 
    fn update;
    fn daemon;
}

pub struct DualCache<K, V>
where
    K: Hash + Eq + Clone,
{
    main: Cache<K, V>,// æ“ä½œ
    sub: Cache<K, V>, //æ˜ å°„æŸ¥è©¢
}
```

 
